{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from mecab import MeCab\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(context='../../data/aihub/eval_context.json', question='../../data/aihub/eval_question.json', model_id='snunlp/KR-SBERT-V40K-klueNLI-augSTS')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = argparse.Namespace()\n",
    "args.context = \"../../data/aihub/eval_context.json\"\n",
    "args.question = \"../../data/aihub/eval_question.json\"\n",
    "args.model_id = \"snunlp/KR-SBERT-V40K-klueNLI-augSTS\"\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.context) as f:\n",
    "    context = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.question) as f:\n",
    "    question = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(context) == len(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25 (0.9084407721630294)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기를 이용한 tokeinizer 선언\n",
    "# 조사 등 일부 품사를 제거\n",
    "# 품사표: https://blog.naver.com/aramjo/221404488280\n",
    "MECAB = MeCab()\n",
    "EXCLUDE = set(\n",
    "    [\n",
    "        \"JKS\",\n",
    "        \"JKC\",\n",
    "        \"JKG\",\n",
    "        \"JKO\",\n",
    "        \"JKB\",\n",
    "        \"JKV\",\n",
    "        \"JKQ\",\n",
    "        \"JX\",\n",
    "        \"JC\",\n",
    "        \"EP\",\n",
    "        \"EF\",\n",
    "        \"EC\",\n",
    "        \"ETN\",\n",
    "        \"ETM\",\n",
    "        \"SF\",\n",
    "        \"SSC\",\n",
    "        \"SSO\",\n",
    "        \"SY\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(sent):\n",
    "    tokens = []\n",
    "    for w, t in MECAB.pos(sent):\n",
    "        if t not in EXCLUDE:\n",
    "            tokens.append(w)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "context_keys = np.array(list(context.keys()))\n",
    "tokenized_contexts = [tokenizer(context[k]) for k in context_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25 class 생성\n",
    "bm25 = BM25Okapi(tokenized_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ffee864acf4eaebb23fb1018d9533a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9084407721630294\n"
     ]
    }
   ],
   "source": [
    " # 평가\n",
    "score = 0.0\n",
    "for key, value in tqdm(question.items()):\n",
    "    # question tokenize\n",
    "    tokenized_question = tokenizer(value[\"question\"])\n",
    "    # score 계산\n",
    "    scores = bm25.get_scores(tokenized_question)\n",
    "    # score 역순으로 정렬\n",
    "    rank = np.argsort(-scores)[:10]  # top 10\n",
    "    # mrr 계산\n",
    "    rank_keys = context_keys[rank]\n",
    "    result = np.where(rank_keys == key)\n",
    "    assert len(result[0]) < 2\n",
    "    if len(result[0]) == 1:\n",
    "        score += 1 / (result[0][0] + 1)\n",
    "print(score / len(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence BERT (0.5799622218413428)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cchyun/miniconda3/envs/rag/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/cchyun/miniconda3/envs/rag/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SentenceBERT 모델 생성\n",
    "model = SentenceTransformer(args.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus embeddings\n",
    "context_keys = np.array(list(context.keys()))\n",
    "context_values = [context[k] for k in context_keys]\n",
    "context_embeddings = model.encode(context_values, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014bca421a224dad8ca06f999301b9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5799622218413428\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "score = 0.0\n",
    "for key, value in tqdm(question.items()):\n",
    "    # query embedding\n",
    "    question_embedding = model.encode(value[\"question\"], normalize_embeddings=True)\n",
    "    # score 계산\n",
    "    scores = np.dot(context_embeddings, question_embedding)\n",
    "    # score 역순으로 정렬\n",
    "    rank = np.argsort(-scores)[:10]  # top 10\n",
    "    # mrr 계산\n",
    "    rank_keys = context_keys[rank]\n",
    "    result = np.where(rank_keys == key)\n",
    "    assert len(result[0]) < 2\n",
    "    if len(result[0]) == 1:\n",
    "        score += 1 / (result[0][0] + 1)\n",
    "print(score / len(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
